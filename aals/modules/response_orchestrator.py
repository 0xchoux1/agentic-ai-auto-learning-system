#!/usr/bin/env python3
"""
AALS Module 9: Response Orchestrator
å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆåˆ¶å¾¡ãƒ»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

PURPOSE: å…¨ã¦ã®AALSãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ±åˆã—ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®SREãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚
         äººé–“ã®æ‰¿èªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã€è‡ªå‹•åŒ–ãƒ¬ãƒ™ãƒ«èª¿æ•´ã‚’æä¾›ã€‚
DEPENDENCIES: Module 2-8 (å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«)
INPUT: IncidentEvent, WorkflowRequest
OUTPUT: IncidentResponse, WorkflowStatus, Dashboard
INTEGRATION: æœ€ä¸Šä½åˆ¶å¾¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import asyncio
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
import uuid
from pathlib import Path

from aals.core.config import get_config_manager
from aals.core.logger import get_logger, AuditAction, AuditLogEntry, audit_log

# ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from aals.modules.slack_alert_reader import SlackAlertReader, SlackMessage
from aals.modules.prometheus_analyzer import PrometheusAnalyzer, SystemHealthReport
from aals.modules.github_issues_searcher import GitHubIssuesSearcher, GitHubSearchReport
from aals.modules.llm_wrapper import LLMWrapper, LLMResponse
from aals.modules.alert_correlator import (
    AlertCorrelator, CorrelatedAlert, IntegratedRecommendation, 
    EscalationDecision, EscalationLevel
)
from aals.modules.ssh_executor import (
    SSHExecutor, CommandRequest, ExecutionReport, PermissionLevel,
    SSHTarget, ApprovalStatus
)

logger = get_logger(__name__)


class WorkflowStage(Enum):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ®µéš"""
    DETECTION = "detection"              # ç•°å¸¸æ¤œçŸ¥
    CORRELATION = "correlation"          # ç›¸é–¢åˆ†æ
    ANALYSIS = "analysis"               # è©³ç´°åˆ†æ
    PLANNING = "planning"               # å¯¾å¿œè¨ˆç”»
    APPROVAL = "approval"               # æ‰¿èªãƒ—ãƒ­ã‚»ã‚¹
    EXECUTION = "execution"             # å®Ÿè¡Œ
    MONITORING = "monitoring"           # å®Ÿè¡Œç›£è¦–
    COMPLETION = "completion"           # å®Œäº†


class WorkflowStatus(Enum):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹"""
    PENDING = "pending"
    RUNNING = "running"
    WAITING_APPROVAL = "waiting_approval"
    EXECUTING = "executing"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    ESCALATED = "escalated"


class AutomationLevel(Enum):
    """è‡ªå‹•åŒ–ãƒ¬ãƒ™ãƒ«"""
    MANUAL = "manual"                   # å®Œå…¨æ‰‹å‹•
    SEMI_AUTO = "semi_auto"            # åŠè‡ªå‹•ï¼ˆæ‰¿èªå¿…è¦ï¼‰
    AUTO_MONITOR = "auto_monitor"      # è‡ªå‹•å®Ÿè¡Œ+ç›£è¦–
    FULL_AUTO = "full_auto"            # å®Œå…¨è‡ªå‹•


@dataclass
class IncidentEvent:
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆ"""
    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    source: str = ""                    # slack, prometheus, github, manual
    event_type: str = ""               # alert, metric_threshold, issue_created
    severity: str = "info"             # critical, high, medium, low, info
    title: str = ""
    description: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)
    correlation_id: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "event_id": self.event_id,
            "source": self.source,
            "event_type": self.event_type,
            "severity": self.severity,
            "title": self.title,
            "description": self.description,
            "metadata": self.metadata,
            "timestamp": self.timestamp.isoformat(),
            "correlation_id": self.correlation_id
        }


@dataclass
class WorkflowStep:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—"""
    step_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    stage: WorkflowStage = WorkflowStage.DETECTION
    name: str = ""
    description: str = ""
    module: str = ""                   # å®Ÿè¡Œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å
    action: str = ""                   # å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    parameters: Dict[str, Any] = field(default_factory=dict)
    status: str = "pending"           # pending, running, completed, failed
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    execution_time: float = 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "step_id": self.step_id,
            "stage": self.stage.value,
            "name": self.name,
            "description": self.description,
            "module": self.module,
            "action": self.action,
            "parameters": self.parameters,
            "status": self.status,
            "result": self.result,
            "error_message": self.error_message,
            "started_at": self.started_at.isoformat() if self.started_at else None,
            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
            "execution_time": self.execution_time
        }


@dataclass
class WorkflowInstance:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹"""
    workflow_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    incident_event: IncidentEvent = None
    automation_level: AutomationLevel = AutomationLevel.SEMI_AUTO
    status: WorkflowStatus = WorkflowStatus.PENDING
    current_stage: WorkflowStage = WorkflowStage.DETECTION
    steps: List[WorkflowStep] = field(default_factory=list)
    approvals: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    execution_context: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    created_by: str = "system"
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "workflow_id": self.workflow_id,
            "incident_event": self.incident_event.to_dict() if self.incident_event else None,
            "automation_level": self.automation_level.value,
            "status": self.status.value,
            "current_stage": self.current_stage.value,
            "steps": [step.to_dict() for step in self.steps],
            "approvals": self.approvals,
            "execution_context": self.execution_context,
            "created_at": self.created_at.isoformat(),
            "started_at": self.started_at.isoformat() if self.started_at else None,
            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
            "created_by": self.created_by
        }


@dataclass
class IncidentResponse:
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œçµæœ"""
    incident_id: str
    workflow_id: str
    status: str
    summary: str
    actions_taken: List[Dict[str, Any]]
    recommendations: List[str]
    metrics: Dict[str, Any]
    duration_minutes: float
    automation_level: str
    human_interventions: int
    timestamp: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "incident_id": self.incident_id,
            "workflow_id": self.workflow_id,
            "status": self.status,
            "summary": self.summary,
            "actions_taken": self.actions_taken,
            "recommendations": self.recommendations,
            "metrics": self.metrics,
            "duration_minutes": self.duration_minutes,
            "automation_level": self.automation_level,
            "human_interventions": self.human_interventions,
            "timestamp": self.timestamp.isoformat()
        }


class WorkflowTemplate:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"""
    
    @staticmethod
    def create_standard_incident_workflow() -> List[WorkflowStep]:
        """æ¨™æº–ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
        return [
            WorkflowStep(
                stage=WorkflowStage.DETECTION,
                name="Alert Collection",
                description="Collect alerts from multiple sources",
                module="alert_correlator",
                action="collect_alert_contexts",
                parameters={"time_window_minutes": 30}
            ),
            WorkflowStep(
                stage=WorkflowStage.CORRELATION,
                name="Alert Correlation",
                description="Analyze correlations between alerts",
                module="alert_correlator",
                action="analyze_correlations",
                parameters={}
            ),
            WorkflowStep(
                stage=WorkflowStage.ANALYSIS,
                name="System Health Analysis",
                description="Analyze current system health",
                module="prometheus_analyzer",
                action="analyze_system_health",
                parameters={"hours_back": 1}
            ),
            WorkflowStep(
                stage=WorkflowStage.ANALYSIS,
                name="Similar Issues Search",
                description="Search for similar past issues",
                module="github_searcher",
                action="search_similar_incidents",
                parameters={"max_results": 5}
            ),
            WorkflowStep(
                stage=WorkflowStage.ANALYSIS,
                name="LLM Analysis",
                description="AI-powered incident analysis",
                module="llm_wrapper",
                action="analyze_incident",
                parameters={}
            ),
            WorkflowStep(
                stage=WorkflowStage.PLANNING,
                name="Generate Recommendations",
                description="Generate integrated recommendations",
                module="alert_correlator",
                action="generate_integrated_recommendations",
                parameters={}
            ),
            WorkflowStep(
                stage=WorkflowStage.PLANNING,
                name="Escalation Decision",
                description="Determine escalation requirements",
                module="alert_correlator",
                action="make_escalation_decision",
                parameters={}
            ),
            WorkflowStep(
                stage=WorkflowStage.EXECUTION,
                name="Execute Commands",
                description="Execute recommended commands",
                module="ssh_executor",
                action="execute_command",
                parameters={"dry_run": True}  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯dry-run
            ),
            WorkflowStep(
                stage=WorkflowStage.MONITORING,
                name="Post-Execution Monitoring",
                description="Monitor system after execution",
                module="prometheus_analyzer",
                action="analyze_system_health",
                parameters={"hours_back": 0.5}
            )
        ]
    
    @staticmethod
    def create_performance_investigation_workflow() -> List[WorkflowStep]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æŸ»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
        return [
            WorkflowStep(
                stage=WorkflowStage.DETECTION,
                name="Performance Metrics Collection",
                description="Collect performance-related metrics",
                module="prometheus_analyzer",
                action="analyze_system_health",
                parameters={"hours_back": 2}
            ),
            WorkflowStep(
                stage=WorkflowStage.ANALYSIS,
                name="Trend Analysis",
                description="Analyze performance trends",
                module="prometheus_analyzer",
                action="analyze_metric_trend",
                parameters={}
            ),
            WorkflowStep(
                stage=WorkflowStage.ANALYSIS,
                name="Performance Issue Search",
                description="Search for similar performance issues",
                module="github_searcher",
                action="search_similar_incidents",
                parameters={"keywords": ["performance", "slow", "timeout"]}
            ),
            WorkflowStep(
                stage=WorkflowStage.PLANNING,
                name="Performance Recommendations",
                description="Generate performance improvement recommendations",
                module="llm_wrapper",
                action="analyze_metrics",
                parameters={}
            )
        ]


class ResponseOrchestrator:
    """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.config_manager = get_config_manager()
        self.config = self.config_manager.get_module_config("response_orchestrator")
        
        # ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
        self.slack_reader = SlackAlertReader()
        self.prometheus_analyzer = PrometheusAnalyzer()
        self.github_searcher = GitHubIssuesSearcher()
        self.llm_wrapper = LLMWrapper()
        self.alert_correlator = AlertCorrelator()
        self.ssh_executor = SSHExecutor()
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­å®š
        self.default_automation_level = AutomationLevel(
            self.config.config.get("default_automation_level", "semi_auto")
        )
        self.max_concurrent_workflows = self.config.config.get("max_concurrent_workflows", 10)
        self.workflow_timeout_minutes = self.config.config.get("workflow_timeout_minutes", 60)
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
        self.active_workflows: Dict[str, WorkflowInstance] = {}
        self.workflow_history: List[WorkflowInstance] = []
        
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
        self.modules = {
            "slack_reader": self.slack_reader,
            "prometheus_analyzer": self.prometheus_analyzer,
            "github_searcher": self.github_searcher,
            "llm_wrapper": self.llm_wrapper,
            "alert_correlator": self.alert_correlator,
            "ssh_executor": self.ssh_executor
        }
        
        # æ‰¿èªè€…è¨­å®š
        self.approvers = self.config.config.get("approvers", {})
        
        logger.info("Response Orchestrator initialized",
                   automation_level=self.default_automation_level.value,
                   max_workflows=self.max_concurrent_workflows)
    
    async def start(self):
        """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼é–‹å§‹"""
        # ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–‹å§‹
        await self.ssh_executor.start()
        
        logger.info("Response Orchestrator started")
    
    async def stop(self):
        """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼åœæ­¢"""
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for workflow_id in list(self.active_workflows.keys()):
            await self.cancel_workflow(workflow_id, "System shutdown")
        
        # ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åœæ­¢
        await self.ssh_executor.stop()
        
        logger.info("Response Orchestrator stopped")
    
    async def verify_setup(self) -> bool:
        """ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ç¢ºèª"""
        try:
            # å…¨ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç¢ºèª
            module_status = {}
            for name, module in self.modules.items():
                if hasattr(module, 'verify_setup'):
                    status = await module.verify_setup()
                    module_status[name] = status
                else:
                    module_status[name] = True
            
            successful_modules = sum(1 for status in module_status.values() if status)
            total_modules = len(module_status)
            
            logger.info("Response Orchestrator setup verification completed",
                       successful_modules=successful_modules,
                       total_modules=total_modules,
                       module_status=module_status)
            
            # åŠæ•°ä»¥ä¸Šã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã§ã‚ã‚Œã°å‹•ä½œå¯èƒ½
            return successful_modules >= total_modules // 2
            
        except Exception as e:
            logger.error("Response Orchestrator setup verification failed",
                        error=str(e), exception_type=type(e).__name__)
            return False
    
    async def handle_incident(
        self,
        incident_event: IncidentEvent,
        automation_level: Optional[AutomationLevel] = None,
        workflow_template: Optional[str] = None
    ) -> WorkflowInstance:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå‡¦ç†"""
        
        # è‡ªå‹•åŒ–ãƒ¬ãƒ™ãƒ«æ±ºå®š
        automation_level = automation_level or self._determine_automation_level(incident_event)
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé¸æŠ
        workflow_steps = self._get_workflow_template(workflow_template, incident_event)
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        workflow = WorkflowInstance(
            incident_event=incident_event,
            automation_level=automation_level,
            steps=workflow_steps,
            status=WorkflowStatus.PENDING
        )
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«è¿½åŠ 
        self.active_workflows[workflow.workflow_id] = workflow
        
        # ç›£æŸ»ãƒ­ã‚°
        audit_log(AuditLogEntry(
            action=AuditAction.CREATE,
            resource=f"incident_workflow:{workflow.workflow_id}",
            result="success",
            details=f"Incident: {incident_event.title}, Automation: {automation_level.value}",
            risk_level=self._get_risk_level(incident_event.severity)
        ))
        
        logger.info("Incident workflow created",
                   workflow_id=workflow.workflow_id,
                   incident_id=incident_event.event_id,
                   automation_level=automation_level.value,
                   steps_count=len(workflow_steps))
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹
        asyncio.create_task(self._execute_workflow(workflow))
        
        return workflow
    
    def _determine_automation_level(self, incident_event: IncidentEvent) -> AutomationLevel:
        """è‡ªå‹•åŒ–ãƒ¬ãƒ™ãƒ«æ±ºå®š"""
        severity = incident_event.severity.lower()
        source = incident_event.source.lower()
        
        # é‡è¦åº¦ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®š
        if severity == "critical":
            # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã¯æ‰‹å‹•æ‰¿èªå¿…é ˆ
            return AutomationLevel.SEMI_AUTO
        elif severity == "high":
            return AutomationLevel.SEMI_AUTO
        elif severity == "medium":
            return AutomationLevel.AUTO_MONITOR
        else:
            return AutomationLevel.FULL_AUTO
    
    def _get_workflow_template(
        self, 
        template_name: Optional[str], 
        incident_event: IncidentEvent
    ) -> List[WorkflowStep]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå–å¾—"""
        if template_name == "performance":
            return WorkflowTemplate.create_performance_investigation_workflow()
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ¨™æº–ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ
            return WorkflowTemplate.create_standard_incident_workflow()
    
    def _get_risk_level(self, severity: str) -> str:
        """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«å¤‰æ›"""
        risk_map = {
            "critical": "critical",
            "high": "high",
            "medium": "medium",
            "low": "low",
            "info": "low"
        }
        return risk_map.get(severity.lower(), "medium")
    
    async def _execute_workflow(self, workflow: WorkflowInstance):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
        try:
            workflow.status = WorkflowStatus.RUNNING
            workflow.started_at = datetime.now()
            
            logger.info("Workflow execution started",
                       workflow_id=workflow.workflow_id)
            
            for step in workflow.steps:
                # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œå‰ãƒã‚§ãƒƒã‚¯
                if workflow.status in [WorkflowStatus.CANCELLED, WorkflowStatus.FAILED]:
                    break
                
                # ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¸æ›´æ–°
                workflow.current_stage = step.stage
                
                # æ‰¿èªãŒå¿…è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã‹ãƒã‚§ãƒƒã‚¯
                if self._requires_approval(workflow, step):
                    workflow.status = WorkflowStatus.WAITING_APPROVAL
                    await self._request_approval(workflow, step)
                    
                    # æ‰¿èªå¾…ã¡
                    approval_granted = await self._wait_for_approval(workflow, step)
                    if not approval_granted:
                        workflow.status = WorkflowStatus.FAILED
                        break
                    
                    workflow.status = WorkflowStatus.RUNNING
                
                # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
                success = await self._execute_step(workflow, step)
                
                if not success:
                    workflow.status = WorkflowStatus.FAILED
                    break
            
            # å®Œäº†å‡¦ç†
            if workflow.status == WorkflowStatus.RUNNING:
                workflow.status = WorkflowStatus.COMPLETED
                workflow.completed_at = datetime.now()
                
                # å®Œäº†å¾Œã®å¾Œå‡¦ç†
                await self._post_execution_processing(workflow)
            
            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å±¥æ­´ã«ç§»å‹•
            self._archive_workflow(workflow)
            
            logger.info("Workflow execution completed",
                       workflow_id=workflow.workflow_id,
                       status=workflow.status.value,
                       duration=f"{(workflow.completed_at - workflow.started_at).total_seconds():.1f}s" if workflow.completed_at else "N/A")
            
        except Exception as e:
            logger.error("Workflow execution failed",
                        workflow_id=workflow.workflow_id,
                        error=str(e),
                        exception_type=type(e).__name__)
            
            workflow.status = WorkflowStatus.FAILED
            workflow.completed_at = datetime.now()
            self._archive_workflow(workflow)
    
    def _requires_approval(self, workflow: WorkflowInstance, step: WorkflowStep) -> bool:
        """æ‰¿èªãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯"""
        # è‡ªå‹•åŒ–ãƒ¬ãƒ™ãƒ«ã«ã‚ˆã‚‹åˆ¤å®š
        if workflow.automation_level == AutomationLevel.MANUAL:
            return True
        elif workflow.automation_level == AutomationLevel.FULL_AUTO:
            return False
        
        # å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ã¯æ‰¿èªå¿…è¦
        if step.stage == WorkflowStage.EXECUTION:
            if step.module == "ssh_executor":
                return True
        
        # é«˜ãƒªã‚¹ã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯æ‰¿èªå¿…è¦
        high_risk_actions = ["execute_command", "restart_service", "scale_resources"]
        if step.action in high_risk_actions:
            return True
        
        return False
    
    async def _request_approval(self, workflow: WorkflowInstance, step: WorkflowStep):
        """æ‰¿èªãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        approval_id = str(uuid.uuid4())
        
        # å¿…è¦ãªæ‰¿èªè€…æ±ºå®š
        required_approvers = self._get_required_approvers(workflow, step)
        
        # æ‰¿èªãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨˜éŒ²
        workflow.approvals[approval_id] = {
            "step_id": step.step_id,
            "required_approvers": required_approvers,
            "approvals": {},
            "status": "pending",
            "created_at": datetime.now().isoformat(),
            "expires_at": (datetime.now() + timedelta(minutes=30)).isoformat()
        }
        
        logger.info("Approval requested",
                   workflow_id=workflow.workflow_id,
                   step_id=step.step_id,
                   approval_id=approval_id,
                   required_approvers=required_approvers)
    
    def _get_required_approvers(self, workflow: WorkflowInstance, step: WorkflowStep) -> List[str]:
        """å¿…è¦æ‰¿èªè€…å–å¾—"""
        severity = workflow.incident_event.severity.lower()
        
        if step.stage == WorkflowStage.EXECUTION:
            if severity == "critical":
                return self.approvers.get("critical", ["sre-lead", "on-call"])
            elif severity == "high":
                return self.approvers.get("high", ["sre-team"])
            else:
                return self.approvers.get("medium", ["sre-team"])
        
        return self.approvers.get("default", ["sre-team"])
    
    async def _wait_for_approval(self, workflow: WorkflowInstance, step: WorkflowStep) -> bool:
        """æ‰¿èªå¾…ã¡"""
        timeout_minutes = 30
        check_interval = 5  # 5ç§’é–“éš”ã§ãƒã‚§ãƒƒã‚¯
        max_checks = (timeout_minutes * 60) // check_interval
        
        for _ in range(max_checks):
            await asyncio.sleep(check_interval)
            
            # æ‰¿èªçŠ¶æ³ãƒã‚§ãƒƒã‚¯
            for approval_id, approval_data in workflow.approvals.items():
                if approval_data["step_id"] == step.step_id:
                    if approval_data["status"] == "approved":
                        return True
                    elif approval_data["status"] == "rejected":
                        return False
            
            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚ŒãŸå ´åˆ
            if workflow.status == WorkflowStatus.CANCELLED:
                return False
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        logger.warning("Approval timeout",
                      workflow_id=workflow.workflow_id,
                      step_id=step.step_id)
        return False
    
    async def _execute_step(self, workflow: WorkflowInstance, step: WorkflowStep) -> bool:
        """ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ"""
        step.status = "running"
        step.started_at = datetime.now()
        
        logger.info("Executing workflow step",
                   workflow_id=workflow.workflow_id,
                   step_id=step.step_id,
                   module=step.module,
                   action=step.action)
        
        try:
            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—
            module = self.modules.get(step.module)
            if not module:
                raise ValueError(f"Module not found: {step.module}")
            
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            result = await self._call_module_action(
                module, 
                step.action, 
                step.parameters,
                workflow.execution_context
            )
            
            # çµæœã‚’å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ä¿å­˜
            workflow.execution_context[f"{step.module}_{step.action}"] = result
            
            step.result = result
            step.status = "completed"
            step.completed_at = datetime.now()
            step.execution_time = (step.completed_at - step.started_at).total_seconds()
            
            logger.info("Workflow step completed",
                       workflow_id=workflow.workflow_id,
                       step_id=step.step_id,
                       execution_time=f"{step.execution_time:.2f}s")
            
            return True
            
        except Exception as e:
            step.status = "failed"
            step.error_message = str(e)
            step.completed_at = datetime.now()
            step.execution_time = (step.completed_at - step.started_at).total_seconds()
            
            logger.error("Workflow step failed",
                        workflow_id=workflow.workflow_id,
                        step_id=step.step_id,
                        error=str(e),
                        exception_type=type(e).__name__)
            
            return False
    
    async def _call_module_action(
        self, 
        module: Any, 
        action: str, 
        parameters: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Any:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å‘¼ã³å‡ºã—"""
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è£œå®Œ
        enhanced_params = self._enhance_parameters(parameters, context)
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        if action == "collect_alert_contexts":
            return await module.collect_alert_contexts(**enhanced_params)
        elif action == "analyze_correlations":
            contexts = context.get("alert_correlator_collect_alert_contexts", [])
            return module.analyze_correlations(contexts)
        elif action == "analyze_system_health":
            return await module.analyze_system_health(**enhanced_params)
        elif action == "search_similar_incidents":
            # å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰èª¬æ˜æ–‡ã‚’å–å¾—
            description = self._extract_incident_description(context)
            enhanced_params["description"] = description
            return await module.search_similar_incidents(**enhanced_params)
        elif action == "analyze_incident":
            description = self._extract_incident_description(context)
            return await module.analyze_incident(description)
        elif action == "generate_integrated_recommendations":
            correlation = context.get("alert_correlator_analyze_correlations", [])
            if correlation:
                return await module.generate_integrated_recommendations(correlation[0])
            return None
        elif action == "make_escalation_decision":
            correlation = context.get("alert_correlator_analyze_correlations", [])
            if correlation:
                return module.make_escalation_decision(correlation[0])
            return None
        elif action == "execute_command":
            # SSHå®Ÿè¡Œã¯ç‰¹åˆ¥å‡¦ç†
            return await self._execute_ssh_commands(module, enhanced_params, context)
        else:
            # æ±ç”¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            if hasattr(module, action):
                method = getattr(module, action)
                if asyncio.iscoroutinefunction(method):
                    return await method(**enhanced_params)
                else:
                    return method(**enhanced_params)
            else:
                raise ValueError(f"Action not found: {action} on module {type(module).__name__}")
    
    def _enhance_parameters(self, parameters: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§æ‹¡å¼µ"""
        enhanced = parameters.copy()
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¿…è¦ãªå€¤ã‚’è‡ªå‹•è£œå®Œ
        # ä¾‹: æ™‚é–“çª“ã€ç›¸é–¢IDã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹åãªã©
        
        return enhanced
    
    def _extract_incident_description(self, context: Dict[str, Any]) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆèª¬æ˜ã‚’æŠ½å‡º"""
        descriptions = []
        
        # ç›¸é–¢åˆ†æçµæœã‹ã‚‰
        correlations = context.get("alert_correlator_analyze_correlations", [])
        if correlations:
            descriptions.append(f"Correlated incident with {len(correlations)} alerts")
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹åˆ†æã‹ã‚‰
        health_report = context.get("prometheus_analyzer_analyze_system_health")
        if health_report:
            descriptions.append(f"System health: {health_report.overall_health}")
        
        return "; ".join(descriptions) if descriptions else "System incident detected"
    
    async def _execute_ssh_commands(
        self, 
        ssh_executor: SSHExecutor, 
        parameters: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> ExecutionReport:
        """SSH ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ"""
        
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ã‚’æŠ½å‡º
        recommendations = context.get("alert_correlator_generate_integrated_recommendations")
        
        if not recommendations:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚³ãƒãƒ³ãƒ‰
            command = "systemctl status"
            targets = [SSHTarget(host="localhost")]
        else:
            # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æœ€åˆã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ
            immediate_actions = recommendations.immediate_actions
            if immediate_actions:
                command = immediate_actions[0]  # ç°¡æ˜“çš„ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾ä½¿ç”¨
                targets = [SSHTarget(host="localhost")]  # å®Ÿç’°å¢ƒã§ã¯é©åˆ‡ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ±ºå®š
            else:
                command = "echo 'No actions recommended'"
                targets = [SSHTarget(host="localhost")]
        
        # å®Ÿè¡Œ
        return await ssh_executor.execute_command(
            command=command,
            targets=targets,
            permission_level=PermissionLevel.READ_ONLY,
            dry_run=parameters.get("dry_run", True),
            requested_by="orchestrator"
        )
    
    async def _post_execution_processing(self, workflow: WorkflowInstance):
        """å®Ÿè¡Œå¾Œå‡¦ç†"""
        # çµæœã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        summary = self._generate_workflow_summary(workflow)
        
        # ç›£æŸ»ãƒ­ã‚°
        audit_log(AuditLogEntry(
            action=AuditAction.COMPLETE,
            resource=f"incident_workflow:{workflow.workflow_id}",
            result="success",
            details=summary,
            risk_level=self._get_risk_level(workflow.incident_event.severity)
        ))
        
        logger.info("Workflow post-processing completed",
                   workflow_id=workflow.workflow_id,
                   summary=summary[:100])
    
    def _generate_workflow_summary(self, workflow: WorkflowInstance) -> str:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        completed_steps = [s for s in workflow.steps if s.status == "completed"]
        failed_steps = [s for s in workflow.steps if s.status == "failed"]
        total_time = (workflow.completed_at - workflow.started_at).total_seconds() if workflow.completed_at else 0
        
        return (f"Workflow completed: {len(completed_steps)}/{len(workflow.steps)} steps successful, "
                f"{len(failed_steps)} failed, duration: {total_time:.1f}s")
    
    def _archive_workflow(self, workflow: WorkflowInstance):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–"""
        if workflow.workflow_id in self.active_workflows:
            del self.active_workflows[workflow.workflow_id]
        
        self.workflow_history.append(workflow)
        
        # å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™
        max_history = self.config.config.get("max_workflow_history", 1000)
        if len(self.workflow_history) > max_history:
            self.workflow_history = self.workflow_history[-max_history:]
    
    async def approve_workflow_step(
        self, 
        workflow_id: str, 
        approval_id: str, 
        approver: str, 
        decision: bool
    ) -> bool:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—æ‰¿èª"""
        
        if workflow_id not in self.active_workflows:
            logger.warning("Workflow not found for approval",
                          workflow_id=workflow_id)
            return False
        
        workflow = self.active_workflows[workflow_id]
        
        if approval_id not in workflow.approvals:
            logger.warning("Approval request not found",
                          workflow_id=workflow_id,
                          approval_id=approval_id)
            return False
        
        approval_data = workflow.approvals[approval_id]
        
        # æ‰¿èªè¨˜éŒ²
        approval_data["approvals"][approver] = {
            "decision": decision,
            "timestamp": datetime.now().isoformat()
        }
        
        # æ‹’å¦ã®å ´åˆ
        if not decision:
            approval_data["status"] = "rejected"
            logger.info("Workflow step rejected",
                       workflow_id=workflow_id,
                       approval_id=approval_id,
                       approver=approver)
            return True
        
        # å…¨æ‰¿èªè€…ã®æ‰¿èªç¢ºèª
        required_approvers = approval_data["required_approvers"]
        approvals = approval_data["approvals"]
        
        if len(approvals) >= len(required_approvers):
            approval_data["status"] = "approved"
            logger.info("Workflow step approved",
                       workflow_id=workflow_id,
                       approval_id=approval_id,
                       approvers=list(approvals.keys()))
        
        return True
    
    async def cancel_workflow(self, workflow_id: str, reason: str = "User cancelled") -> bool:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        
        if workflow_id not in self.active_workflows:
            return False
        
        workflow = self.active_workflows[workflow_id]
        workflow.status = WorkflowStatus.CANCELLED
        workflow.completed_at = datetime.now()
        
        # å®Ÿè¡Œä¸­ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’åœæ­¢
        for step in workflow.steps:
            if step.status == "running":
                step.status = "cancelled"
                step.completed_at = datetime.now()
        
        logger.info("Workflow cancelled",
                   workflow_id=workflow_id,
                   reason=reason)
        
        self._archive_workflow(workflow)
        return True
    
    def get_active_workflows(self) -> List[WorkflowInstance]:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å–å¾—"""
        return list(self.active_workflows.values())
    
    def get_workflow_status(self, workflow_id: str) -> Optional[WorkflowInstance]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹å–å¾—"""
        if workflow_id in self.active_workflows:
            return self.active_workflows[workflow_id]
        
        # å±¥æ­´ã‹ã‚‰ã‚‚æ¤œç´¢
        for workflow in self.workflow_history:
            if workflow.workflow_id == workflow_id:
                return workflow
        
        return None
    
    def get_pending_approvals(self) -> List[Dict[str, Any]]:
        """æ‰¿èªå¾…ã¡ãƒªã‚¹ãƒˆå–å¾—"""
        pending = []
        
        for workflow in self.active_workflows.values():
            if workflow.status == WorkflowStatus.WAITING_APPROVAL:
                for approval_id, approval_data in workflow.approvals.items():
                    if approval_data["status"] == "pending":
                        pending.append({
                            "workflow_id": workflow.workflow_id,
                            "approval_id": approval_id,
                            "incident_title": workflow.incident_event.title,
                            "step_name": next(
                                (s.name for s in workflow.steps if s.step_id == approval_data["step_id"]), 
                                "Unknown Step"
                            ),
                            "required_approvers": approval_data["required_approvers"],
                            "created_at": approval_data["created_at"],
                            "expires_at": approval_data["expires_at"]
                        })
        
        return pending
    
    def generate_dashboard_data(self) -> Dict[str, Any]:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        now = datetime.now()
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±è¨ˆ
        active_count = len(self.active_workflows)
        waiting_approval_count = len([w for w in self.active_workflows.values() 
                                    if w.status == WorkflowStatus.WAITING_APPROVAL])
        
        # æœ€è¿‘ã®å±¥æ­´çµ±è¨ˆ
        recent_history = [w for w in self.workflow_history 
                         if w.completed_at and (now - w.completed_at).days < 7]
        
        completed_count = len([w for w in recent_history if w.status == WorkflowStatus.COMPLETED])
        failed_count = len([w for w in recent_history if w.status == WorkflowStatus.FAILED])
        
        # å¹³å‡å®Ÿè¡Œæ™‚é–“
        execution_times = []
        for workflow in recent_history:
            if workflow.started_at and workflow.completed_at:
                duration = (workflow.completed_at - workflow.started_at).total_seconds()
                execution_times.append(duration)
        
        avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0
        
        return {
            "timestamp": now.isoformat(),
            "active_workflows": {
                "total": active_count,
                "waiting_approval": waiting_approval_count,
                "running": active_count - waiting_approval_count
            },
            "recent_history": {
                "completed": completed_count,
                "failed": failed_count,
                "success_rate": completed_count / (completed_count + failed_count) if (completed_count + failed_count) > 0 else 0
            },
            "performance": {
                "avg_execution_time_seconds": avg_execution_time,
                "total_workflows_processed": len(recent_history)
            },
            "pending_approvals": len(self.get_pending_approvals())
        }


# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ä¾‹
async def main():
    """ä½¿ç”¨ä¾‹"""
    orchestrator = ResponseOrchestrator()
    
    # é–‹å§‹
    await orchestrator.start()
    
    try:
        # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ç¢ºèª
        if not await orchestrator.verify_setup():
            print("âŒ Setup verification failed")
            return
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ
        incident = IncidentEvent(
            source="prometheus",
            event_type="metric_threshold",
            severity="high",
            title="High API Response Time",
            description="API response time exceeded 5 seconds threshold",
            metadata={"metric": "api_response_time", "value": 6.2, "threshold": 5.0}
        )
        
        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå‡¦ç†é–‹å§‹
        workflow = await orchestrator.handle_incident(
            incident,
            automation_level=AutomationLevel.SEMI_AUTO
        )
        
        print(f"ğŸ“Š Incident Workflow Started")
        print(f"   Workflow ID: {workflow.workflow_id}")
        print(f"   Automation Level: {workflow.automation_level.value}")
        print(f"   Steps: {len(workflow.steps)}")
        
        # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿
        dashboard = orchestrator.generate_dashboard_data()
        print(f"\nğŸ“ˆ Dashboard")
        print(f"   Active Workflows: {dashboard['active_workflows']['total']}")
        print(f"   Pending Approvals: {dashboard['pending_approvals']}")
        
        # æ‰¿èªå¾…ã¡ãƒªã‚¹ãƒˆ
        pending = orchestrator.get_pending_approvals()
        print(f"\nâ³ Pending Approvals: {len(pending)}")
        
    finally:
        # åœæ­¢
        await orchestrator.stop()


if __name__ == "__main__":
    asyncio.run(main())